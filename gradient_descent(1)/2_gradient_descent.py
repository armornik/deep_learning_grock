weight = 0.5
goal_pred = 0.8
input = 0.5

for iteration in range(20):
    pred = input * weight
    clear_error = (pred - goal_pred)  # Чистая ошибка
    error = clear_error ** 2
    direction_and_amount = clear_error * input  # Масштабирование, обращение знака и остановка
    weight = weight - direction_and_amount
    print("Error:" + str(error) + " Prediction:" + str(pred))



# ЧТО ХРАНИТ ПЕРЕМЕННАЯ DIRECTION_AND_AMOUNT?
# Переменная direction_and_amount представляет, как должен измениться
# вес. Чтобы получить ее значение, код сначала О вычисляет чистую ошибку
# (pred - goal_pred). (Подробнее об этом чуть ниже.) А затем О умножает ее
# на input, чтобы выполнить масштабирование, обращение знака и остановку,
# превращая чистую ошибку в значение, пригодное для изменения weight.

# ЧТО ТАКОЕ ЧИСТАЯ ОШИБКА?
# Чистая ошибка — это разность (pred - goal_pred), определяющая направление
# и величину промаха. Если это положительное число, значит, прогноз
# слишком велик, и наоборот. Если это большое число, значит, вы сильно промахнулись,
# и так далее.

# ЧТО ТАКОЕ МАСШТАБИРОВАНИЕ, ОБРАЩЕНИЕ ЗНАКА И ОСТАНОВКА?
# Эти три характеристики описывают общий эффект преобразования чистой
# ошибки в абсолютную величину изменения веса. Это необходимо для обхода
# трех основных крайних случаев, когда чистой ошибки недостаточно для выбора
# хорошей величины изменения веса.
# ЧТО ТАКОЕ ОСТАНОВКА
# Остановка — это первый (и самый простой) эффект, обусловленный умножением
# чистой ошибки на input. Представьте, что вы подключили проигрыватель
# компакт-дисков к своей стереосистеме. Если теперь включить полную
# громкость, но не включить проигрыватель, изменение громкости ничего не
# даст. Остановка — это похожий эффект в нейронных сетях. Если input получит
# значение 0, тогда direction_and_amount также получит значение 0.
# Обучения (изменения громкости) не будет происходить, когда переменная
# input будет равна 0, потому что нечему будет учиться. Каждое значение
# weight будет давать одну и ту же ошибку error, и попытка изменить ее не
# будет давать результата, потому что pred всегда будет равна 0.
# ЧТО ТАКОЕ ОБРАЩЕНИЕ ЗНАКА?
# Это самый сложный и важный, как мне кажется, эффект. Обычно (когда
# input имеет положительное значение) смещение веса вверх влечет смещение
# прогноза тоже вверх. Но если input получит отрицательное значение,
# вес начнет изменяться в другом направлении! При отрицательном
# значении input смещение веса вверх заставит прогноз смещаться вниз. Это
# и есть обращение знака! Как этого добиться? Все просто, умножение чистой
# ошибки на input меняет знак direction_and_amount, если input имеет
# отрицательное значение. Такое обращение знака гарантирует изменение
# веса в правильном направлении, даже когда input имеет отрицательное
# значение.
# ЧТО ТАКОЕ МАСШТАБИРОВАНИЕ?
# Масштабирование — это третий эффект, вызываемый умножением чистой
# ошибки на input. По логике, если input имеет большое значение, значит,
# и вес нужно изменить на большую величину. Это в большей степени побочный
# эффект, потом что часто выходит из-под контроля. Позднее мы познакомимся
# с альфа-коэффициентом, который будем использовать, когда такое
# случится.
